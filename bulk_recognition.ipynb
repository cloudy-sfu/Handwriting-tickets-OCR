{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KikKEfjtFk_C"
   },
   "source": [
    "<center>\n",
    "\n",
    "# Handwriting Tickets OCR\n",
    "*github/cloudy-sfu*\n",
    "\n",
    "</center>\n",
    "\n",
    "This repository shows how to recognizing tables with Chinese characters and numbers in handwriting tickets.\n",
    "\n",
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 9701,
     "status": "ok",
     "timestamp": 1681058452346,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "vRXx37O6GS9E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from itertools import count\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypdfium2 as pdfium\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tqdm import tqdm\n",
    "from openvino.inference_engine import IECore\n",
    "from lstm_rnn_ctc.ctccodec import CtcCodec\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmXAT8PtGJOc"
   },
   "source": [
    "Input scanned tickets to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681058452347,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "dmbPoI60FZE7"
   },
   "outputs": [],
   "source": [
    "filename = \"data/style1.pdf\" #@param [\"data/style1.pdf\", \"data/style2.pdf\", \"data/style3.pdf\"] {allow-input: true}\n",
    "name = os.path.splitext(os.path.split(filename)[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKkNss_YGOjN"
   },
   "source": [
    "# Table layout\n",
    "\n",
    "Convert PDF to image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681058452347,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "j4133MNVJySq"
   },
   "outputs": [],
   "source": [
    "pdf = pdfium.PdfDocument(filename)\n",
    "# https://pypdfium2.readthedocs.io/en/stable/python_api.html#pypdfium2._helpers.page.PdfPage.render_base\n",
    "n_pages = len(pdf)\n",
    "pages_generator = pdf.render_to(pdfium.BitmapConv.numpy_ndarray, page_indices=range(n_pages),\n",
    "                             scale=300 / 72, greyscale=True)  # scale unit: 72 dpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzbgQ1mdL2kC"
   },
   "source": [
    "Use a counter to generate page numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681058452347,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "Z3D34KTHL5ee"
   },
   "outputs": [],
   "source": [
    "page_number_generator = count()\n",
    "cells = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2teIgHYMCHP"
   },
   "source": [
    "Analyze page layouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22396,
     "status": "ok",
     "timestamp": 1681058476820,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "TLAO9oE4MBm8",
    "outputId": "0d1b3122-ff3f-4a54-9d3c-3b52d0428d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing page 168/168."
     ]
    }
   ],
   "source": [
    "with open(f'raw/{name}_tables.pkl', 'wb') as f:\n",
    "    for page, channel in pages_generator:\n",
    "        page_number = next(page_number_generator)  # counter from 0\n",
    "        # Flush the same line:\n",
    "        # use `print()` to start a new line, giving space to the first \"cursor up\" command, before the loop\n",
    "        # use the suffix `\\x1b[1A\\x1b[2K` in each print to move the cursor up and clean the line\n",
    "        # if the string length monotonically increase in each iteration, we simplify this version as the following\n",
    "        print(f'\\rAnalyzing page {page_number + 1}/{n_pages}.', end='')\n",
    "\n",
    "        reversed_page = cv2.bitwise_not(page[:, :, 0])  # conver to black background\n",
    "        # significantly faster than cv2.RETR_TREE\n",
    "        # extracting subtree from a hierarchy unsolved -> use cv2.RETR_EXTERNAL insteead of cv2.RETR_TREE\n",
    "        # not analyzing hierarchy inside the table in this function\n",
    "        contours, hierarchy = cv2.findContours(reversed_page, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        size = [cv2.contourArea(x) for x in contours]  # Slightly faster than np.vectorize but not significant\n",
    "        largest_outer_contour = contours[np.argmax(size)]\n",
    "        # automatically rotate the table\n",
    "        # https://jdhao.github.io/2019/02/23/crop_rotated_rectangle_opencv/\n",
    "        box = cv2.minAreaRect(largest_outer_contour)\n",
    "        w, h = box[1]\n",
    "        source_points = cv2.boxPoints(box)\n",
    "        if box[2] > 45:  # (45, 90) left is lower and right is higher\n",
    "            destination_points = np.array([[0, 0], [h, 0], [h, w], [0, w]])\n",
    "            transformation = cv2.getPerspectiveTransform(source_points.astype('float32'),\n",
    "                                                        destination_points.astype('float32'))\n",
    "            rotated_table = cv2.warpPerspective(reversed_page, transformation, (int(h), int(w)))\n",
    "        else:  # (0, 45) left is higher and right is lower\n",
    "            destination_points = np.array([[0, h], [0, 0], [w, 0], [w, h]])\n",
    "            transformation = cv2.getPerspectiveTransform(source_points.astype('float32'),\n",
    "                                                        destination_points.astype('float32'))\n",
    "            rotated_table = cv2.warpPerspective(reversed_page, transformation, (int(w), int(h)))\n",
    "        pickle.dump(rotated_table, f)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(rotated_table, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        h, w = rotated_table.shape\n",
    "        sq_lb, sq_ub = max(784, h * w * 6e-4), h * w * 0.9\n",
    "        positions = np.array([cv2.boundingRect(x) for x in contours if sq_lb < cv2.contourArea(x) < sq_ub])\n",
    "        # when contourArea > sq_lb, cell w*h > sq_lb w.p.1\n",
    "        positions = positions[positions[:, 2] * positions[:, 3] < sq_ub, :]\n",
    "        cells_per_table = pd.DataFrame(columns=['x', 'y', 'w', 'h'], data=positions)\n",
    "        cells_per_table['table_id'] = page_number\n",
    "        cells_per_table['table_w'] = w\n",
    "        cells_per_table['table_h'] = h\n",
    "\n",
    "        cells.append(cells_per_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1681058482430,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "18wxqTq4M-vm"
   },
   "outputs": [],
   "source": [
    "cells = pd.concat(cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oax99cTRNljG"
   },
   "source": [
    "# Cell correspondence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681058483587,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "xvRdPieiNrjT"
   },
   "outputs": [],
   "source": [
    "positions = pd.DataFrame({\n",
    "    'relative_x': cells['x'] / cells['table_w'],\n",
    "    'relative_y': cells['y'] / cells['table_h']\n",
    "})\n",
    "n_tables = cells['table_id'].max() + 1\n",
    "min_pts = int(n_tables * 0.4)\n",
    "\n",
    "# empirical method\n",
    "relative_w = cells['w'] / cells['table_w']\n",
    "relative_h = cells['h'] / cells['table_h']\n",
    "eps = np.sqrt(relative_w.min() ** 2 + relative_h.min() ** 2) * 1.22475\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_pts, n_jobs=-1)\n",
    "cells['labels'] = dbscan.fit_predict(positions)\n",
    "cells = cells.loc[cells['labels'] != -1, :]\n",
    "cells_labeled = cells.drop_duplicates(subset=['table_id', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681058485483,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "LLOZUjQQN9zC"
   },
   "outputs": [],
   "source": [
    "n_tables = cells_labeled['table_id'].max() + 1\n",
    "cells_subtotals = []\n",
    "for (label, cells_subset) in cells_labeled.groupby('labels'):\n",
    "    cells_subtotals.append({\n",
    "        'label': label + 1,\n",
    "        'frequency': cells_subset.shape[0] / n_tables,\n",
    "        'avg_relative_x': (cells_subset['x'] / cells_subset['table_w']).mean(),\n",
    "        'avg_relative_y': (cells_subset['y'] / cells_subset['table_h']).mean(),\n",
    "        'avg_relative_w': (cells_subset['w'] / cells_subset['table_w']).mean(),\n",
    "        'avg_relative_h': (cells_subset['h'] / cells_subset['table_h']).mean(),\n",
    "    })\n",
    "anchors = pd.DataFrame(cells_subtotals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1681058488493,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "4Qb2gqwsOShD",
    "outputId": "e42b750f-f114-45de-e7bf-36a155548bb1"
   },
   "outputs": [],
   "source": [
    "with open(f\"raw/{name}_tables.pkl\", \"rb\") as f:\n",
    "    table = pickle.load(f)\n",
    "table = cv2.bitwise_not(table)\n",
    "table = cv2.cvtColor(table[:, :, np.newaxis], cv2.COLOR_GRAY2RGB)\n",
    "h, w, _ = table.shape\n",
    "border_width = int(max(min(h / 540, w / 540), 2))\n",
    "for _, anchor in anchors.iterrows():\n",
    "    x1 = int(anchor['avg_relative_x'] * w)\n",
    "    y1 = int(anchor['avg_relative_y'] * h)\n",
    "    x2 = x1 + int(anchor['avg_relative_w'] * w)\n",
    "    y2 = y1 + int(anchor['avg_relative_h'] * h)\n",
    "    cv2.rectangle(table, (x1, y1), (x2, y2), (255, 0, 0), border_width)\n",
    "    # https://stackoverflow.com/questions/16615662/how-to-write-text-on-a-image-in-windows-using-python-opencv2\n",
    "    cv2.putText(table, f\"[{int(anchor['label'])}]{int(anchor['frequency'] * 100)}\",\n",
    "                org=(x1, y2), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.6, color=(255, 0, 0),\n",
    "                thickness=border_width)\n",
    "Image.fromarray(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk2Bj5YsPMAF"
   },
   "source": [
    "# Table OCR\n",
    "Perform handwriting Chinese OCR of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1681058497889,
     "user": {
      "displayName": "Yixiao Lu",
      "userId": "17143726773017254738"
     },
     "user_tz": -720
    },
    "id": "gaQXDmy_2rwr"
   },
   "outputs": [],
   "source": [
    "model_xml = 'intel/handwritten-simplified-chinese-recognition-0001/FP16-INT8/handwritten-simplified-chinese' \\\n",
    "            '-recognition-0001.xml'\n",
    "model_bin = 'intel/handwritten-simplified-chinese-recognition-0001/FP16-INT8/handwritten-simplified-chinese' \\\n",
    "            '-recognition-0001.bin'\n",
    "# Prepare the language specific information, characters list and codec method\n",
    "chars_list_file = 'lstm_rnn_ctc/scut_ept.txt'\n",
    "with open(chars_list_file, 'r') as f:\n",
    "    model_characters = f.read()\n",
    "codec = CtcCodec(model_characters)\n",
    "ie = IECore()  # Plugin initialization for specified device and load extensions library if specified\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)  # Read OpenVino IR model\n",
    "net_exec = ie.load_network(network=net, device_name='CPU')\n",
    "_, _, net_h, net_w = net.input_info['actual_input'].input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQuGXxMPPNO5",
    "outputId": "be33318c-19d1-4c78-f5b6-0da4065667ce"
   },
   "outputs": [],
   "source": [
    "text = pd.DataFrame(index=np.arange(n_pages), columns=anchors['label'].values)\n",
    "with open(f'raw/{name}_tables.pkl', 'rb') as f:\n",
    "    for j in tqdm(range(n_pages)):\n",
    "        table = pickle.load(f)\n",
    "\n",
    "        tb_h, tb_w = table.shape\n",
    "        x = np.round(anchors['avg_relative_x'].values * tb_w).astype(int)\n",
    "        y = np.round(anchors['avg_relative_y'].values * tb_h).astype(int)\n",
    "        w = np.round(anchors['avg_relative_w'].values * tb_w).astype(int)\n",
    "        h = np.round(anchors['avg_relative_h'].values * tb_h).astype(int)\n",
    "        table = cv2.bitwise_not(table)  # convert to white background\n",
    "        \n",
    "        for i in range(anchors.shape[0]):\n",
    "            cell = table[y[i]:y[i] + h[i], x[i]:x[i] + w[i]]\n",
    "            \n",
    "            # this part is applicable when text alignment is horizontal\n",
    "            cell_h, cell_w = cell.shape\n",
    "            # when slimmer than the requirement of model, keep the aspect ratio and pad white\n",
    "            adjusted_cell_w = int(cell_w / cell_h * net_h)\n",
    "            if adjusted_cell_w <= net_w:\n",
    "                processed_cell = np.full((net_h, net_w), 255)\n",
    "                processed_cell[:, :adjusted_cell_w] = cv2.resize(\n",
    "                    cell, (adjusted_cell_w, net_h), interpolation=cv2.INTER_AREA)\n",
    "            # when wider than the requirement of model,\n",
    "            else:\n",
    "                processed_cell = cv2.resize(cell, (net_w, net_h), interpolation=cv2.INTER_AREA)\n",
    "            processed_cell = processed_cell[np.newaxis, np.newaxis, :, :]\n",
    "            res = net_exec.infer(inputs={'actual_input': processed_cell})\n",
    "            res_decoded = codec.decode(res['output'])\n",
    "            text.loc[j, anchors.loc[i, 'label']] = ''.join(res_decoded)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boqzabP6Piv0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text.to_excel(f'results/{name}_text.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDtXX3P+YJPh4235U+WlUO",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
